{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo con GraphSage - Ensayo"
      ],
      "metadata": {
        "id": "wx7Zu38C9sRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar bibliotecas necesarias\n",
        "!pip install networkx transformers pysentimiento pandas numpy scikit-learn"
      ],
      "metadata": {
        "id": "Vv3BcS859x39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "501e8c85-3977-4727-818f-c0ccda3c800f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: pysentimiento in /usr/local/lib/python3.11/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from pysentimiento) (1.7.0)\n",
            "Requirement already satisfied: datasets>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from pysentimiento) (2.14.4)\n",
            "Requirement already satisfied: emoji>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from pysentimiento) (2.14.1)\n",
            "Requirement already satisfied: spacy>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from pysentimiento) (3.8.7)\n",
            "Requirement already satisfied: torch!=2.0.1,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pysentimiento) (2.6.0+cu124)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.27.2->pysentimiento) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.1->pysentimiento) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.1->pysentimiento) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.1->pysentimiento) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.1->pysentimiento) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets>=2.10.1->pysentimiento) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.1->pysentimiento) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (0.16.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.5.0->pysentimiento) (3.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,>=2.0.0->pysentimiento) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,>=2.0.0->pysentimiento) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.1->pysentimiento) (1.20.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.5.0->pysentimiento) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->pysentimiento) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->pysentimiento) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.5.0->pysentimiento) (0.4.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.5.0->pysentimiento) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3.5.0->pysentimiento) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.5.0->pysentimiento) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.5.0->pysentimiento) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.5.0->pysentimiento) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.5.0->pysentimiento) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.5.0->pysentimiento) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.5.0->pysentimiento) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio torch-sparse torch-scatter torch-geometric pyg-lib -y"
      ],
      "metadata": {
        "id": "lmyPtTIYFh9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e61b41-ed4c-4557-f9b2-052a8f162b73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Found existing installation: torch_sparse 0.6.18+pt26cu124\n",
            "Uninstalling torch_sparse-0.6.18+pt26cu124:\n",
            "  Successfully uninstalled torch_sparse-0.6.18+pt26cu124\n",
            "Found existing installation: torch_scatter 2.1.2+pt26cu124\n",
            "Uninstalling torch_scatter-2.1.2+pt26cu124:\n",
            "  Successfully uninstalled torch_scatter-2.1.2+pt26cu124\n",
            "Found existing installation: torch_geometric 2.5.3\n",
            "Uninstalling torch_geometric-2.5.3:\n",
            "  Successfully uninstalled torch_geometric-2.5.3\n",
            "Found existing installation: pyg-lib 0.4.0+pt26cu124\n",
            "Uninstalling pyg-lib-0.4.0+pt26cu124:\n",
            "  Successfully uninstalled pyg-lib-0.4.0+pt26cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.6.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
      ],
      "metadata": {
        "id": "lZW_6mxACDLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d84cd03f-5e80-4e95-c031-131412c49888"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.6.0\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0) (3.0.2)\n",
            "Using cached https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (768.5 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.6.0+cu124 torchaudio-2.6.0+cu124 torchvision-0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter==2.1.2+pt26cu124 torch-sparse==0.6.18+pt26cu124 torch-geometric==2.5.3 -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "id": "T6E3u9RHM6Jd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25720f04-6edc-4392-de2a-85827ddea008"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting torch-scatter==2.1.2+pt26cu124\n",
            "  Using cached https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_scatter-2.1.2%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "Collecting torch-sparse==0.6.18+pt26cu124\n",
            "  Using cached https://data.pyg.org/whl/torch-2.6.0%2Bcu124/torch_sparse-0.6.18%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (5.0 MB)\n",
            "Collecting torch-geometric==2.5.3\n",
            "  Using cached torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse==0.6.18+pt26cu124) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (2.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (3.1.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (3.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.5.3) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.3) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.3) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.3) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric==2.5.3) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.5.3) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.3) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.3) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.5.3) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.5.3) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.5.3) (3.6.0)\n",
            "Using cached torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.5.3 torch-scatter-2.1.2+pt26cu124 torch-sparse-0.6.18+pt26cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg-lib==0.4.0+pt26cu124 -f https://data.pyg.org/whl/torch-2.6.0+cu124.html"
      ],
      "metadata": {
        "id": "vvjy3kHHFuP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3e2ec2-323e-4af3-a8a5-4e0c14f04f7c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+cu124.html\n",
            "Collecting pyg-lib==0.4.0+pt26cu124\n",
            "  Using cached https://data.pyg.org/whl/torch-2.6.0%2Bcu124/pyg_lib-0.4.0%2Bpt26cu124-cp311-cp311-linux_x86_64.whl (4.7 MB)\n",
            "Installing collected packages: pyg-lib\n",
            "Successfully installed pyg-lib-0.4.0+pt26cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)  # Debería ser 2.6.0\n",
        "print(torch.version.cuda)  # Debería ser 12.4 (para cu124)\n",
        "\n",
        "import torch_geometric\n",
        "print(torch_geometric.__version__)  # Debe imprimir la versión sin errores"
      ],
      "metadata": {
        "id": "ZPB479YeCQBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ba2062-500e-4831-e4ec-7a0303c15db1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "12.4\n",
            "2.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())  # Debe ser True si hay GPU, sino False"
      ],
      "metadata": {
        "id": "N3mzh7yYC1Ey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7b4b85-5d9f-4a3e-d427-861bdffd6d9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch"
      ],
      "metadata": {
        "id": "RRLY-x6Z-eMu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subir los archivos CSV\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "CvGR4sMO-4t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar los CSV en DataFrames\n",
        "emprendimientos = pd.read_csv('emprendimientos.csv')\n",
        "publicaciones = pd.read_csv('publicaciones.csv')\n",
        "comentarios = pd.read_csv('comentarios.csv')\n",
        "seguidores = pd.read_csv('seguidores.csv')\n",
        "emprendimiento_tematica = pd.read_csv('emprendimiento_tematica.csv')\n",
        "municipios = pd.read_csv('municipios.csv')\n",
        "alcances = pd.read_csv('alcance.csv')\n",
        "tematicas = pd.read_csv('tematicas.csv')"
      ],
      "metadata": {
        "id": "yhocIqzy_FYr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# emprendimientos = pd.read_csv('emprendimientos.csv', encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "v1zbNRjRAGI_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Seguidores:\\n\", seguidores.head())"
      ],
      "metadata": {
        "id": "g6eOKsRY_aiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec679f18-7f31-426c-d117-4f60648b6937"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seguidores:\n",
            "    id_seguidores  id_emprendimiento  cantidad\n",
            "0              1                  1       312\n",
            "1              2                  2       387\n",
            "2              3                  3       173\n",
            "3              4                  4       146\n",
            "4              5                  5       231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Municipios:\\n\", municipios.head())"
      ],
      "metadata": {
        "id": "DidnqQIc_owo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffff9a09-521e-4202-c1fd-4f2799679fc8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Municipios:\n",
            "    id_municipio municipio\n",
            "0             1   Popayán\n",
            "1             2    Silvia\n",
            "2             3    Totoró\n",
            "3             4   Cajibío\n",
            "4             5  Piendamó\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Alcances:\\n\", alcances.head())"
      ],
      "metadata": {
        "id": "oPby9vYG_zeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88caf1bf-6381-4bcc-f350-b3e1c47f0946"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alcances:\n",
            "    id_alcance      tipo\n",
            "0           1     Local\n",
            "1           2  Regional\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Temáticas:\\n\", tematicas.head())"
      ],
      "metadata": {
        "id": "0gSNOmDA_2tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0fc9a6b-cc53-4acc-d11a-a72d905175ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temáticas:\n",
            "    id_tematica                  nombre\n",
            "0            1  Agricultura sostenible\n",
            "1            2               Reciclaje\n",
            "2            3       Tecnología social\n",
            "3            4              Artesanías\n",
            "4            5       Salud comunitaria\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Comentarios:\\n\", comentarios.head())"
      ],
      "metadata": {
        "id": "o5fgmSKx_5qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1307f66-c8b2-4ba1-c791-ac018a2a8e65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comentarios:\n",
            "    id_comentario                                         comentario  \\\n",
            "0              1  ¡Qué bacano! Voy este sábado a sembrar. 🌱 #Hue...   \n",
            "1              2  ¿Dónde es el taller en Popayán, parce? #Huerto...   \n",
            "2              3  Buen proyecto, pero falta más info del horario...   \n",
            "3              4  Me encanta la idea, pero ojalá sea más largo. ...   \n",
            "4              5  ¡Qué chimba! @JuanCa, vente al taller. 🙌 #Sost...   \n",
            "\n",
            "   id_publicacion  \n",
            "0               1  \n",
            "1               1  \n",
            "2               1  \n",
            "3               1  \n",
            "4               1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construcción Grafo"
      ],
      "metadata": {
        "id": "_ISrAZC8ALqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el grafo\n",
        "G = nx.Graph()\n",
        "\n",
        "# Agregar nodos (emprendimientos)\n",
        "for _, row in emprendimientos.iterrows():\n",
        "    # Obtener temáticas asociadas\n",
        "    temas = emprendimiento_tematica[emprendimiento_tematica['id_emprendimiento'] == row['id_emprendimiento']]['id_tematica'].tolist()\n",
        "    # Atributos del nodo\n",
        "    node_attrs = {\n",
        "        'nombre_emprendimiento': row['nombre_emprendimiento'],\n",
        "        'descripcion': row['descripcion'] if pd.notna(row['descripcion']) else '',\n",
        "        'redes_sociales': row['redes_sociales'] if pd.notna(row['redes_sociales']) else '',\n",
        "        'sitio_web': row['sitio_web'],\n",
        "        'id_municipio_origen': row['id_municipio_origen'],\n",
        "        'id_alcance': row['id_alcance'],\n",
        "        'tematicas': temas\n",
        "    }\n",
        "    G.add_node(row['id_emprendimiento'], **node_attrs)\n",
        "\n",
        "print(f\"Nodos creados: {G.number_of_nodes()}\")"
      ],
      "metadata": {
        "id": "0Bqa63do_9G0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b158108a-295f-4c9f-9a75-7d95b1c0eb09"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodos creados: 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear aristas basadas en interacciones\n",
        "for _, pub in publicaciones.iterrows():\n",
        "    id_emprendimiento = pub['id_emprendimiento']\n",
        "    # Conectar emprendimientos que comparten temáticas en publicaciones (simplificación, ya que no tenemos datos de quién comentó)\n",
        "    related_emprendimientos = emprendimiento_tematica[\n",
        "        emprendimiento_tematica['id_tematica'].isin(\n",
        "            emprendimiento_tematica[emprendimiento_tematica['id_emprendimiento'] == id_emprendimiento]['id_tematica']\n",
        "        )\n",
        "    ]['id_emprendimiento'].unique()\n",
        "    for rel_emp in related_emprendimientos:\n",
        "        if rel_emp != id_emprendimiento and rel_emp in G.nodes:\n",
        "            weight = pub['n_likes'] if pd.notna(pub['n_likes']) else 0\n",
        "            G.add_edge(id_emprendimiento, rel_emp, weight=weight + 1)\n",
        "\n",
        "# Crear aristas basadas en similitudes\n",
        "for emp1 in G.nodes:\n",
        "    for emp2 in G.nodes:\n",
        "        if emp1 < emp2:  # Evitar duplicados\n",
        "            emp1_attrs = G.nodes[emp1]\n",
        "            emp2_attrs = G.nodes[emp2]\n",
        "            # Similitud por temática\n",
        "            temas_comunes = len(set(emp1_attrs['tematicas']) & set(emp2_attrs['tematicas']))\n",
        "            # Similitud por municipio y alcance\n",
        "            same_municipio = 1 if emp1_attrs['id_municipio_origen'] == emp2_attrs['id_municipio_origen'] else 0\n",
        "            same_alcance = 1 if emp1_attrs['id_alcance'] == emp2_attrs['id_alcance'] else 0\n",
        "            # Ponderar arista\n",
        "            weight = temas_comunes + same_municipio + same_alcance\n",
        "            if weight > 0:\n",
        "                G.add_edge(emp1, emp2, weight=weight)\n",
        "\n",
        "# Agregar peso basado en seguidores\n",
        "for _, row in seguidores.iterrows():\n",
        "    id_emprendimiento = row['id_emprendimiento']\n",
        "    if id_emprendimiento in G.nodes:\n",
        "        G.nodes[id_emprendimiento]['seguidores'] = row['cantidad']\n",
        "        # Aumentar peso de aristas existentes según seguidores\n",
        "        for emp2 in G.neighbors(id_emprendimiento):\n",
        "            G[id_emprendimiento][emp2]['weight'] += row['cantidad'] / 1000  # Normalizar\n",
        "\n",
        "print(f\"Aristas creadas: {G.number_of_edges()}\")"
      ],
      "metadata": {
        "id": "6Bscqt5wAdcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1db5ec-72d1-4a78-ac38-c9a64f628ab0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aristas creadas: 1127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizar atributos numéricos\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Calcular total de likes por emprendimiento\n",
        "likes_por_emprendimiento = publicaciones.groupby('id_emprendimiento')['n_likes'].sum().reset_index()\n",
        "likes_por_emprendimiento.columns = ['id_emprendimiento', 'total_likes']\n",
        "\n",
        "# Combinar likes y seguidores\n",
        "emprendimientos_features = emprendimientos.merge(likes_por_emprendimiento, on='id_emprendimiento', how='left').fillna({'total_likes': 0})\n",
        "emprendimientos_features = emprendimientos_features.merge(seguidores[['id_emprendimiento', 'cantidad']], on='id_emprendimiento', how='left').fillna({'cantidad': 0})\n",
        "\n",
        "# Normalizar total_likes y cantidad\n",
        "numeric_features = scaler.fit_transform(emprendimientos_features[['total_likes', 'cantidad']])\n",
        "emprendimientos_features[['total_likes_norm', 'cantidad_norm']] = numeric_features\n",
        "\n",
        "# Codificar atributos categóricos\n",
        "onehot_encoder_municipio = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "municipio_encoded = onehot_encoder_municipio.fit_transform(emprendimientos[['id_municipio_origen']])\n",
        "municipio_encoded_df = pd.DataFrame(municipio_encoded, columns=onehot_encoder_municipio.get_feature_names_out(['id_municipio_origen']))\n",
        "\n",
        "onehot_encoder_alcance = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "alcance_encoded = onehot_encoder_alcance.fit_transform(emprendimientos[['id_alcance']])\n",
        "alcance_encoded_df = pd.DataFrame(alcance_encoded, columns=onehot_encoder_alcance.get_feature_names_out(['id_alcance']))\n",
        "\n",
        "# Codificar temáticas (matriz binaria)\n",
        "tematica_encoded = np.zeros((len(emprendimientos), len(tematicas)))\n",
        "for _, row in emprendimiento_tematica.iterrows():\n",
        "    idx_emp = emprendimientos.index[emprendimientos['id_emprendimiento'] == row['id_emprendimiento']].tolist()[0]\n",
        "    idx_tem = tematicas.index[tematicas['id_tematica'] == row['id_tematica']].tolist()[0]\n",
        "    tematica_encoded[idx_emp, idx_tem] = 1\n",
        "tematica_encoded_df = pd.DataFrame(tematica_encoded, columns=[f'tematica_{i}' for i in tematicas['id_tematica']])\n",
        "\n",
        "# Combinar características numéricas y categóricas\n",
        "features_df = pd.concat([emprendimientos_features[['id_emprendimiento', 'total_likes_norm', 'cantidad_norm']],\n",
        "                         municipio_encoded_df, alcance_encoded_df, tematica_encoded_df], axis=1)\n",
        "\n",
        "# Agregar características al grafo\n",
        "for _, row in features_df.iterrows():\n",
        "    if row['id_emprendimiento'] in G.nodes:\n",
        "        G.nodes[row['id_emprendimiento']]['features'] = row.drop('id_emprendimiento').values\n",
        "\n",
        "print(\"Dimensiones de las características:\\n\", features_df.shape)"
      ],
      "metadata": {
        "id": "_8BbZsXYAnku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9baa3943-18ca-4272-e443-b40d1bfdb51f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de las características:\n",
            " (60, 39)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procesar Texto"
      ],
      "metadata": {
        "id": "utp9naAzA9xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar modelo BETO\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
        "model = AutoModel.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")"
      ],
      "metadata": {
        "id": "_8mtSEgmA1bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b42093b-d01a-4ab3-ea9c-7b77104408b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para obtener embeddings de texto\n",
        "def get_text_embedding(text):\n",
        "    if not text or pd.isna(text):\n",
        "        return np.zeros(768)  # Dimensión de BETO\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
      ],
      "metadata": {
        "id": "pSOz7uZtBCVc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duración aproximada del procesamiento de textos: 20 MIN"
      ],
      "metadata": {
        "id": "EvGii7mJGK_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SI ES LA PRIMERA VEZ QUE SE EJECUTA EL ENTORNO:\n",
        "\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# Procesar textos\n",
        "emprendimientos['descripcion_embedding'] = emprendimientos['descripcion'].apply(get_text_embedding)\n",
        "publicaciones['contenido_embedding'] = publicaciones['contenido'].apply(get_text_embedding)\n",
        "comentarios['comentario_embedding'] = comentarios['comentario'].apply(get_text_embedding)\n",
        "\n",
        "# Guardar embeddings de descripción, contenido y comentario\n",
        "np.save('descripcion_embeddings.npy', emprendimientos['descripcion_embedding'].to_numpy())\n",
        "np.save('contenido_embeddings.npy', publicaciones['contenido_embedding'].to_numpy())\n",
        "np.save('comentario_embeddings.npy', comentarios['comentario_embedding'].to_numpy())\n",
        "\n",
        "# Descargar los archivos para guardarlos localmente\n",
        "files.download('descripcion_embeddings.npy')\n",
        "files.download('contenido_embeddings.npy')\n",
        "files.download('comentario_embeddings.npy')\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "v26Vj5fjBUuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subir los archivos .npy si no están en el entorno\n",
        "uploaded = files.upload()  # Sube descripcion_embeddings.npy, contenido_embeddings.npy, comentario_embeddings.npy"
      ],
      "metadata": {
        "id": "MSbXuwG-OZkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar embeddings desde los archivos .npy\n",
        "descripcion_embeddings = np.load('descripcion_embeddings.npy', allow_pickle=True)\n",
        "contenido_embeddings = np.load('contenido_embeddings.npy', allow_pickle=True)\n",
        "comentario_embeddings = np.load('comentario_embeddings.npy', allow_pickle=True)"
      ],
      "metadata": {
        "id": "_vxOs0qHOcwx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Asignar embeddings a los DataFrames\n",
        "emprendimientos['descripcion_embedding'] = list(descripcion_embeddings)\n",
        "publicaciones['contenido_embedding'] = list(contenido_embeddings)\n",
        "comentarios['comentario_embedding'] = list(comentario_embeddings)\n",
        "\n",
        "# Verificar que los embeddings se cargaron correctamente\n",
        "print(\"Ejemplo de embedding de descripción:\", emprendimientos['descripcion_embedding'].iloc[0][:5])\n",
        "print(\"Ejemplo de embedding de contenido:\", publicaciones['contenido_embedding'].iloc[0][:5])\n",
        "print(\"Ejemplo de embedding de comentario:\", comentarios['comentario_embedding'].iloc[0][:5])"
      ],
      "metadata": {
        "id": "CjLdel-QPBST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d613f2-a13c-4495-9047-645c62f5fc15"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de embedding de descripción: [-0.58608776 -0.16883136 -0.05874122 -0.47675955  0.70658404]\n",
            "Ejemplo de embedding de contenido: [-0.5049721  -1.00958     0.6562884  -0.7907445   0.41996792]\n",
            "Ejemplo de embedding de comentario: [-0.46697903 -0.85226786  0.5786223  -0.2946373   0.12753987]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combinar embeddings por emprendimiento\n",
        "for emp_id in G.nodes:\n",
        "    # Embedding de la descripción\n",
        "    desc_embedding = emprendimientos[emprendimientos['id_emprendimiento'] == emp_id]['descripcion_embedding'].iloc[0]\n",
        "\n",
        "    # Promedio de embeddings de publicaciones\n",
        "    pub_embeddings = publicaciones[publicaciones['id_emprendimiento'] == emp_id]['contenido_embedding']\n",
        "    pub_embedding = np.mean([emb for emb in pub_embeddings if emb is not None], axis=0) if len(pub_embeddings) > 0 else np.zeros(768)\n",
        "\n",
        "    # Promedio de embeddings de comentarios\n",
        "    pub_ids = publicaciones[publicaciones['id_emprendimiento'] == emp_id]['id_publicacion'].tolist()\n",
        "    com_embeddings = comentarios[comentarios['id_publicacion'].isin(pub_ids)]['comentario_embedding']\n",
        "    com_embedding = np.mean([emb for emb in com_embeddings if emb is not None], axis=0) if len(com_embeddings) > 0 else np.zeros(768)\n",
        "\n",
        "    # Combinar embeddings\n",
        "    combined_embedding = (desc_embedding + pub_embedding + com_embedding) / 3\n",
        "    G.nodes[emp_id]['text_features'] = combined_embedding\n",
        "\n",
        "print(\"Ejemplo de embedding de texto:\", G.nodes[emprendimientos['id_emprendimiento'].iloc[0]]['text_features'][:5])"
      ],
      "metadata": {
        "id": "B2XvxdxtMVve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e40048-3371-4dcc-b145-560a8bd96f91"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejemplo de embedding de texto: [-0.39286777 -0.5032728   0.33132803 -0.5614875   0.5627695 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "# Combinar características\n",
        "for emp_id in G.nodes:\n",
        "    numeric_categ_features = G.nodes[emp_id].get('features', np.zeros(features_df.shape[1]-1))\n",
        "    text_features = G.nodes[emp_id].get('text_features', np.zeros(768))\n",
        "    combined_features = np.concatenate([numeric_categ_features, text_features])\n",
        "    G.nodes[emp_id]['combined_features'] = combined_features\n",
        "\n",
        "# Convertir a formato PyTorch Geometric\n",
        "node_features = torch.tensor([G.nodes[n]['combined_features'] for n in G.nodes], dtype=torch.float)\n",
        "edge_index = torch.tensor([[e[0], e[1]] for e in G.edges], dtype=torch.long).t()\n",
        "edge_weight = torch.tensor([G[e[0]][e[1]]['weight'] for e in G.edges], dtype=torch.float)\n",
        "\n",
        "# Crear objeto Data\n",
        "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_weight)\n",
        "\n",
        "print(f\"Dimensiones de node_features: {node_features.shape}\")\n",
        "print(f\"Dimensiones de edge_index: {edge_index.shape}\")\n",
        "print(f\"Dimensiones de edge_weight: {edge_weight.shape}\")"
      ],
      "metadata": {
        "id": "eUsbYcUVBbnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce5a8c5-1d42-48eb-ba6a-80491557cddb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de node_features: torch.Size([60, 806])\n",
            "Dimensiones de edge_index: torch.Size([2, 1127])\n",
            "Dimensiones de edge_weight: torch.Size([1127])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1fba999f8978>:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  node_features = torch.tensor([G.nodes[n]['combined_features'] for n in G.nodes], dtype=torch.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumen\n",
        "### Grafo construido:\n",
        "\n",
        "**Nodos**: Emprendimientos con atributos (nombre_emprendimiento, descripcion, redes_sociales, sitio_web, id_municipio_origen, id_alcance, temáticas).\n",
        "\n",
        "**Aristas**: Basadas en interacciones (likes, temáticas compartidas) y similitudes (temáticas, municipio, alcance), ponderadas por n_likes y seguidores.cantidad.\n",
        "\n",
        "**Normalización y codificación**:\n",
        "total_likes y cantidad normalizados.\n",
        "id_municipio_origen, id_alcance y temáticas codificados con one-hot encoding.\n",
        "**Procesamiento de texto**: Embeddings de BETO para descripcion, contenido y comentario, combinados por promedio.\n",
        "\n",
        "**Formato final**: Grafo en formato PyTorch Geometric listo para GraphSAGE."
      ],
      "metadata": {
        "id": "dkJa8uwLGqPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "# Verificar nodos en el grafo\n",
        "print(\"Nodos en G:\", list(G.nodes)[:10])\n",
        "print(\"Número de nodos:\", G.number_of_nodes())\n",
        "\n",
        "# Crear un mapeo de nodos a índices contiguos (0, 1, ..., N-1)\n",
        "nodes = list(G.nodes)\n",
        "mapping = {node: idx for idx, node in enumerate(nodes)}\n",
        "\n",
        "# Verificar que todos los nodos en las aristas estén en el mapeo\n",
        "edges_to_remove = [e for e in G.edges if e[0] not in mapping or e[1] not in mapping]\n",
        "if edges_to_remove:\n",
        "    print(\"Eliminando aristas con nodos inválidos:\", edges_to_remove)\n",
        "    G.remove_edges_from(edges_to_remove)\n",
        "\n",
        "# Actualizar edge_index y edge_attr\n",
        "edge_index_list = [[mapping[e[0]], mapping[e[1]]] for e in G.edges]\n",
        "edge_weight_list = [G[e[0]][e[1]]['weight'] for e in G.edges]\n",
        "edge_index = torch.tensor(edge_index_list, dtype=torch.long).t()\n",
        "edge_weight = torch.tensor(edge_weight_list, dtype=torch.float)\n",
        "\n",
        "print(\"Edge index creado con éxito:\", edge_index.shape)"
      ],
      "metadata": {
        "id": "zc9jAGpkGeCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3dafeb-b9a7-42e9-d2c5-c25889721f76"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodos en G: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "Número de nodos: 60\n",
            "Edge index creado con éxito: torch.Size([2, 1127])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener características de los nodos\n",
        "node_features = torch.tensor([G.nodes[n]['combined_features'] for n in sorted(G.nodes)], dtype=torch.float)\n",
        "\n",
        "# Crear objeto Data\n",
        "data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_weight)\n",
        "\n",
        "print(f\"Dimensiones de node_features: {data.x.shape}\")\n",
        "print(f\"Dimensiones de edge_index: {data.edge_index.shape}\")\n",
        "print(f\"Dimensiones de edge_weight: {data.edge_attr.shape}\")\n",
        "print(f\"Número de nodos: {data.num_nodes}\")\n",
        "print(f\"Número de aristas: {data.num_edges}\")"
      ],
      "metadata": {
        "id": "832yXOvfIIqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468a27f2-9292-481d-ce4a-c0b6908bb16e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de node_features: torch.Size([60, 806])\n",
            "Dimensiones de edge_index: torch.Size([2, 1127])\n",
            "Dimensiones de edge_weight: torch.Size([1127])\n",
            "Número de nodos: 60\n",
            "Número de aristas: 1127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalizar node_features\n",
        "scaler = StandardScaler()\n",
        "data.x = torch.tensor(scaler.fit_transform(data.x), dtype=torch.float)\n",
        "\n",
        "# Verificar varianza de características\n",
        "print(\"Media y desv. estándar de node_features:\", data.x.mean(), data.x.std())\n",
        "\n",
        "# Dividir las aristas\n",
        "transform = RandomLinkSplit(\n",
        "    num_val=0.15,  # 15% para validación\n",
        "    num_test=0.15,  # 15% para prueba\n",
        "    is_undirected=True,  # Grafo no dirigido\n",
        "    add_negative_train_samples=True,  # Generar aristas negativas\n",
        "    neg_sampling_ratio=0.5  # Igual número de aristas negativas que positivas\n",
        ")\n",
        "\n",
        "try:\n",
        "    train_data, val_data, test_data = transform(data)\n",
        "    print(f\"Aristas de entrenamiento positivas: {train_data.edge_label_index.shape}\")\n",
        "    print(f\"Aristas de validación: {val_data.edge_label_index.shape}\")\n",
        "    print(f\"Aristas de prueba: {test_data.edge_label_index.shape}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error al dividir aristas: {e}\")\n",
        "    print(\"Número de aristas:\", data.num_edges)"
      ],
      "metadata": {
        "id": "o10N3VG2KQJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ae7831-273c-4cec-e990-b385db7b3422"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Media y desv. estándar de node_features: tensor(-7.8881e-11) tensor(1.0000)\n",
            "Aristas de entrenamiento positivas: torch.Size([2, 1183])\n",
            "Aristas de validación: torch.Size([2, 253])\n",
            "Aristas de prueba: torch.Size([2, 253])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GraphSAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "        for layer in [self.conv1, self.conv2]:\n",
        "            torch.nn.init.xavier_uniform_(layer.lin_l.weight)\n",
        "            if layer.lin_r is not None:\n",
        "                torch.nn.init.xavier_uniform_(layer.lin_r.weight)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.6, training=self.training)  # Más dropout\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "    def predict_link(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=1)\n",
        "\n",
        "model = GraphSAGE(in_channels=train_data.x.shape[1], hidden_channels=64, out_channels=32)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00005, weight_decay=1e-4)"
      ],
      "metadata": {
        "id": "Hlkl0k01KWu3"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar datos\n",
        "print(\"Nodos en train_data:\", train_data.num_nodes)\n",
        "print(\"Aristas en train_data:\", train_data.edge_index.shape[1])\n",
        "print(\"Aristas etiquetadas (train):\", train_data.edge_label_index.shape[1])\n",
        "print(\"Balance de etiquetas (train):\", train_data.edge_label.unique(return_counts=True))\n",
        "print(\"Aristas etiquetadas (val):\", val_data.edge_label_index.shape[1])\n",
        "print(\"Balance de etiquetas (val):\", val_data.edge_label.unique(return_counts=True))"
      ],
      "metadata": {
        "id": "JWC9RqoW4m1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "512fddd2-e82d-408b-8ec5-2718cc31dcfd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodos en train_data: 60\n",
            "Aristas en train_data: 1578\n",
            "Aristas etiquetadas (train): 1183\n",
            "Balance de etiquetas (train): (tensor([0., 1.]), tensor([394, 789]))\n",
            "Aristas etiquetadas (val): 253\n",
            "Balance de etiquetas (val): (tensor([0., 1.]), tensor([ 84, 169]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar instalaciones\n",
        "import torch\n",
        "import torch_geometric\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"PyTorch Geometric version:\", torch_geometric.__version__)\n",
        "try:\n",
        "    import torch_sparse\n",
        "    print(\"torch-sparse instalado correctamente\")\n",
        "except ImportError:\n",
        "    print(\"torch-sparse no está instalado\")\n",
        "try:\n",
        "    import pyg_lib\n",
        "    print(\"pyg-lib instalado correctamente\")\n",
        "except ImportError:\n",
        "    print(\"pyg-lib no está instalado\")"
      ],
      "metadata": {
        "id": "1vBcTbp6U0sX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6819fa55-299a-4455-ce6a-d551c69c41fb"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "PyTorch Geometric version: 2.5.3\n",
            "torch-sparse instalado correctamente\n",
            "pyg-lib instalado correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_sparse\n",
        "import pyg_lib\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import copy\n",
        "\n",
        "# Crear cargador de datos\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    train_data,\n",
        "    num_neighbors=[15, 5],\n",
        "    batch_size=16,\n",
        "    input_nodes=torch.arange(train_data.num_nodes)\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "train_loader = NeighborLoader(\n",
        "    train_data,\n",
        "    num_neighbors=[30, 15, 10],  # Más vecinos y capas\n",
        "    batch_size=32,  # Ajustar según memoria\n",
        "    input_nodes=torch.arange(train_data.num_nodes)\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = NeighborLoader(\n",
        "    train_data,\n",
        "    num_neighbors=[10, 5],  # 10 vecinos en la 1ª capa, 5 en la 2ª\n",
        "    batch_size=16,\n",
        "    input_nodes=torch.arange(train_data.num_nodes)\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Función de entrenamiento\n",
        "def train():\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        z = model(batch.x, batch.edge_index)\n",
        "        n_id = batch.n_id\n",
        "        node_idx_map = {int(n_id[i]): i for i in range(len(n_id))}\n",
        "        valid_edges = []\n",
        "        for src, dst in batch.edge_label_index.t():\n",
        "            src, dst = int(src), int(dst)\n",
        "            if src in node_idx_map and dst in node_idx_map:\n",
        "                valid_edges.append([node_idx_map[src], node_idx_map[dst]])\n",
        "        if not valid_edges:\n",
        "            continue\n",
        "        edge_label_index_subgraph = torch.tensor(valid_edges, dtype=torch.long).t().to(batch.x.device)\n",
        "        valid_mask = [i for i, (src, dst) in enumerate(batch.edge_label_index.t()) if int(src) in node_idx_map and int(dst) in node_idx_map]\n",
        "        labels_subgraph = batch.edge_label[valid_mask]\n",
        "        scores = model.predict_link(z, edge_label_index_subgraph)\n",
        "        loss = F.binary_cross_entropy_with_logits(scores, labels_subgraph)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate(data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model(data.x, data.edge_index)\n",
        "        scores = model.predict_link(z, data.edge_label_index).sigmoid()\n",
        "        labels = data.edge_label\n",
        "        auc = roc_auc_score(labels.cpu(), scores.cpu())\n",
        "        preds = (scores > 0.5).float()\n",
        "        acc = accuracy_score(labels.cpu(), preds.cpu())\n",
        "    return auc, acc\n",
        "\n",
        "# Early stopping\n",
        "best_auc = 0\n",
        "best_model = None\n",
        "patience = 30\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(1, 601):\n",
        "    loss = train()\n",
        "    if epoch % 10 == 0:\n",
        "        val_auc, val_acc = evaluate(val_data)\n",
        "        print(f'Época {epoch}, Pérdida: {loss:.4f}, AUC Validación: {val_auc:.4f}, Precisión Validación: {val_acc:.4f}')\n",
        "        if val_auc > best_auc:\n",
        "            best_auc = val_auc\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            counter = 0\n",
        "        else:\n",
        "            counter += 1\n",
        "        if counter >= patience:\n",
        "            print(f\"Early stopping en época {epoch}\")\n",
        "            break\n",
        "    else:\n",
        "        print(f'Época {epoch}, Pérdida: {loss:.4f}')\n",
        "\n",
        "# Cargar mejor modelo\n",
        "if best_model is not None:\n",
        "    model.load_state_dict(best_model)"
      ],
      "metadata": {
        "id": "wQZUgWAsKcAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cef1ff2-dc32-4b2d-f952-8d88206a4596"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1, Pérdida: 13.4786\n",
            "Época 2, Pérdida: 11.7904\n",
            "Época 3, Pérdida: 12.1373\n",
            "Época 4, Pérdida: 11.7522\n",
            "Época 5, Pérdida: 11.5666\n",
            "Época 6, Pérdida: 10.2657\n",
            "Época 7, Pérdida: 10.1513\n",
            "Época 8, Pérdida: 9.5111\n",
            "Época 9, Pérdida: 8.5084\n",
            "Época 10, Pérdida: 9.7641, AUC Validación: 0.5837, Precisión Validación: 0.6719\n",
            "Época 11, Pérdida: 8.7974\n",
            "Época 12, Pérdida: 9.3168\n",
            "Época 13, Pérdida: 8.4952\n",
            "Época 14, Pérdida: 7.9206\n",
            "Época 15, Pérdida: 7.2192\n",
            "Época 16, Pérdida: 8.3089\n",
            "Época 17, Pérdida: 7.1732\n",
            "Época 18, Pérdida: 7.1811\n",
            "Época 19, Pérdida: 6.5550\n",
            "Época 20, Pérdida: 6.8010, AUC Validación: 0.6377, Precisión Validación: 0.6798\n",
            "Época 21, Pérdida: 7.0609\n",
            "Época 22, Pérdida: 6.3630\n",
            "Época 23, Pérdida: 6.5903\n",
            "Época 24, Pérdida: 6.6238\n",
            "Época 25, Pérdida: 6.1752\n",
            "Época 26, Pérdida: 6.3347\n",
            "Época 27, Pérdida: 5.7302\n",
            "Época 28, Pérdida: 6.1229\n",
            "Época 29, Pérdida: 6.3052\n",
            "Época 30, Pérdida: 5.6419, AUC Validación: 0.6797, Precisión Validación: 0.7036\n",
            "Época 31, Pérdida: 5.7247\n",
            "Época 32, Pérdida: 5.8258\n",
            "Época 33, Pérdida: 5.3925\n",
            "Época 34, Pérdida: 5.1987\n",
            "Época 35, Pérdida: 5.2471\n",
            "Época 36, Pérdida: 5.1008\n",
            "Época 37, Pérdida: 4.8382\n",
            "Época 38, Pérdida: 4.8630\n",
            "Época 39, Pérdida: 5.2966\n",
            "Época 40, Pérdida: 4.9666, AUC Validación: 0.7063, Precisión Validación: 0.7194\n",
            "Época 41, Pérdida: 4.9796\n",
            "Época 42, Pérdida: 4.6954\n",
            "Época 43, Pérdida: 5.0272\n",
            "Época 44, Pérdida: 4.3626\n",
            "Época 45, Pérdida: 4.5103\n",
            "Época 46, Pérdida: 4.6565\n",
            "Época 47, Pérdida: 4.2994\n",
            "Época 48, Pérdida: 4.3495\n",
            "Época 49, Pérdida: 4.0925\n",
            "Época 50, Pérdida: 4.3995, AUC Validación: 0.7205, Precisión Validación: 0.7312\n",
            "Época 51, Pérdida: 4.1015\n",
            "Época 52, Pérdida: 3.8873\n",
            "Época 53, Pérdida: 4.3974\n",
            "Época 54, Pérdida: 4.0068\n",
            "Época 55, Pérdida: 4.1230\n",
            "Época 56, Pérdida: 3.4420\n",
            "Época 57, Pérdida: 3.9149\n",
            "Época 58, Pérdida: 4.0619\n",
            "Época 59, Pérdida: 4.0854\n",
            "Época 60, Pérdida: 3.5884, AUC Validación: 0.7303, Precisión Validación: 0.7352\n",
            "Época 61, Pérdida: 3.4522\n",
            "Época 62, Pérdida: 3.7190\n",
            "Época 63, Pérdida: 3.6402\n",
            "Época 64, Pérdida: 3.3407\n",
            "Época 65, Pérdida: 3.4168\n",
            "Época 66, Pérdida: 3.3426\n",
            "Época 67, Pérdida: 3.3106\n",
            "Época 68, Pérdida: 3.4525\n",
            "Época 69, Pérdida: 3.3421\n",
            "Época 70, Pérdida: 3.3359, AUC Validación: 0.7330, Precisión Validación: 0.7470\n",
            "Época 71, Pérdida: 3.3297\n",
            "Época 72, Pérdida: 3.2827\n",
            "Época 73, Pérdida: 3.1991\n",
            "Época 74, Pérdida: 3.2799\n",
            "Época 75, Pérdida: 2.9422\n",
            "Época 76, Pérdida: 3.0547\n",
            "Época 77, Pérdida: 3.0171\n",
            "Época 78, Pérdida: 2.6076\n",
            "Época 79, Pérdida: 2.9976\n",
            "Época 80, Pérdida: 3.0173, AUC Validación: 0.7376, Precisión Validación: 0.7510\n",
            "Época 81, Pérdida: 2.8247\n",
            "Época 82, Pérdida: 2.8069\n",
            "Época 83, Pérdida: 2.8706\n",
            "Época 84, Pérdida: 2.8606\n",
            "Época 85, Pérdida: 2.7997\n",
            "Época 86, Pérdida: 2.8025\n",
            "Época 87, Pérdida: 2.7957\n",
            "Época 88, Pérdida: 2.6757\n",
            "Época 89, Pérdida: 2.9114\n",
            "Época 90, Pérdida: 2.7108, AUC Validación: 0.7381, Precisión Validación: 0.7431\n",
            "Época 91, Pérdida: 2.6543\n",
            "Época 92, Pérdida: 2.5678\n",
            "Época 93, Pérdida: 2.5659\n",
            "Época 94, Pérdida: 2.6096\n",
            "Época 95, Pérdida: 2.6522\n",
            "Época 96, Pérdida: 2.5098\n",
            "Época 97, Pérdida: 2.6340\n",
            "Época 98, Pérdida: 2.4760\n",
            "Época 99, Pérdida: 2.3612\n",
            "Época 100, Pérdida: 2.5059, AUC Validación: 0.7391, Precisión Validación: 0.7470\n",
            "Época 101, Pérdida: 2.4045\n",
            "Época 102, Pérdida: 2.4029\n",
            "Época 103, Pérdida: 2.3520\n",
            "Época 104, Pérdida: 2.2905\n",
            "Época 105, Pérdida: 2.3548\n",
            "Época 106, Pérdida: 2.2142\n",
            "Época 107, Pérdida: 2.2847\n",
            "Época 108, Pérdida: 2.1623\n",
            "Época 109, Pérdida: 2.1349\n",
            "Época 110, Pérdida: 2.2757, AUC Validación: 0.7423, Precisión Validación: 0.7589\n",
            "Época 111, Pérdida: 2.2889\n",
            "Época 112, Pérdida: 2.1699\n",
            "Época 113, Pérdida: 2.1758\n",
            "Época 114, Pérdida: 2.1288\n",
            "Época 115, Pérdida: 2.1183\n",
            "Época 116, Pérdida: 2.0899\n",
            "Época 117, Pérdida: 2.0686\n",
            "Época 118, Pérdida: 2.0884\n",
            "Época 119, Pérdida: 2.1149\n",
            "Época 120, Pérdida: 2.0611, AUC Validación: 0.7412, Precisión Validación: 0.7589\n",
            "Época 121, Pérdida: 2.0003\n",
            "Época 122, Pérdida: 2.0780\n",
            "Época 123, Pérdida: 2.0052\n",
            "Época 124, Pérdida: 1.9189\n",
            "Época 125, Pérdida: 1.9421\n",
            "Época 126, Pérdida: 2.0342\n",
            "Época 127, Pérdida: 2.0433\n",
            "Época 128, Pérdida: 1.8122\n",
            "Época 129, Pérdida: 1.8501\n",
            "Época 130, Pérdida: 1.8331, AUC Validación: 0.7406, Precisión Validación: 0.7747\n",
            "Época 131, Pérdida: 1.7767\n",
            "Época 132, Pérdida: 1.9361\n",
            "Época 133, Pérdida: 1.9116\n",
            "Época 134, Pérdida: 1.8907\n",
            "Época 135, Pérdida: 1.8703\n",
            "Época 136, Pérdida: 1.9464\n",
            "Época 137, Pérdida: 1.8414\n",
            "Época 138, Pérdida: 1.7863\n",
            "Época 139, Pérdida: 1.6519\n",
            "Época 140, Pérdida: 1.7578, AUC Validación: 0.7425, Precisión Validación: 0.7747\n",
            "Época 141, Pérdida: 1.7343\n",
            "Época 142, Pérdida: 1.6704\n",
            "Época 143, Pérdida: 1.6580\n",
            "Época 144, Pérdida: 1.6763\n",
            "Época 145, Pérdida: 1.6677\n",
            "Época 146, Pérdida: 1.6599\n",
            "Época 147, Pérdida: 1.6140\n",
            "Época 148, Pérdida: 1.7212\n",
            "Época 149, Pérdida: 1.7078\n",
            "Época 150, Pérdida: 1.5887, AUC Validación: 0.7411, Precisión Validación: 0.7826\n",
            "Época 151, Pérdida: 1.5722\n",
            "Época 152, Pérdida: 1.6190\n",
            "Época 153, Pérdida: 1.5510\n",
            "Época 154, Pérdida: 1.6513\n",
            "Época 155, Pérdida: 1.6575\n",
            "Época 156, Pérdida: 1.5121\n",
            "Época 157, Pérdida: 1.5184\n",
            "Época 158, Pérdida: 1.4536\n",
            "Época 159, Pérdida: 1.6293\n",
            "Época 160, Pérdida: 1.5709, AUC Validación: 0.7448, Precisión Validación: 0.7708\n",
            "Época 161, Pérdida: 1.5341\n",
            "Época 162, Pérdida: 1.4808\n",
            "Época 163, Pérdida: 1.5606\n",
            "Época 164, Pérdida: 1.4973\n",
            "Época 165, Pérdida: 1.4952\n",
            "Época 166, Pérdida: 1.5366\n",
            "Época 167, Pérdida: 1.4557\n",
            "Época 168, Pérdida: 1.4305\n",
            "Época 169, Pérdida: 1.5093\n",
            "Época 170, Pérdida: 1.4365, AUC Validación: 0.7490, Precisión Validación: 0.7628\n",
            "Época 171, Pérdida: 1.3861\n",
            "Época 172, Pérdida: 1.4111\n",
            "Época 173, Pérdida: 1.4165\n",
            "Época 174, Pérdida: 1.3467\n",
            "Época 175, Pérdida: 1.4273\n",
            "Época 176, Pérdida: 1.3637\n",
            "Época 177, Pérdida: 1.3139\n",
            "Época 178, Pérdida: 1.3860\n",
            "Época 179, Pérdida: 1.3903\n",
            "Época 180, Pérdida: 1.3668, AUC Validación: 0.7472, Precisión Validación: 0.7628\n",
            "Época 181, Pérdida: 1.3855\n",
            "Época 182, Pérdida: 1.3732\n",
            "Época 183, Pérdida: 1.3229\n",
            "Época 184, Pérdida: 1.2545\n",
            "Época 185, Pérdida: 1.2901\n",
            "Época 186, Pérdida: 1.3187\n",
            "Época 187, Pérdida: 1.2585\n",
            "Época 188, Pérdida: 1.2985\n",
            "Época 189, Pérdida: 1.3318\n",
            "Época 190, Pérdida: 1.2751, AUC Validación: 0.7461, Precisión Validación: 0.7668\n",
            "Época 191, Pérdida: 1.2465\n",
            "Época 192, Pérdida: 1.3508\n",
            "Época 193, Pérdida: 1.3326\n",
            "Época 194, Pérdida: 1.2779\n",
            "Época 195, Pérdida: 1.2178\n",
            "Época 196, Pérdida: 1.3077\n",
            "Época 197, Pérdida: 1.3067\n",
            "Época 198, Pérdida: 1.1791\n",
            "Época 199, Pérdida: 1.2512\n",
            "Época 200, Pérdida: 1.1947, AUC Validación: 0.7449, Precisión Validación: 0.7668\n",
            "Época 201, Pérdida: 1.1184\n",
            "Época 202, Pérdida: 1.1398\n",
            "Época 203, Pérdida: 1.1748\n",
            "Época 204, Pérdida: 1.2238\n",
            "Época 205, Pérdida: 1.1974\n",
            "Época 206, Pérdida: 1.1311\n",
            "Época 207, Pérdida: 1.2445\n",
            "Época 208, Pérdida: 1.2287\n",
            "Época 209, Pérdida: 1.1309\n",
            "Época 210, Pérdida: 1.1488, AUC Validación: 0.7434, Precisión Validación: 0.7708\n",
            "Época 211, Pérdida: 1.2132\n",
            "Época 212, Pérdida: 1.1163\n",
            "Época 213, Pérdida: 1.2131\n",
            "Época 214, Pérdida: 1.1896\n",
            "Época 215, Pérdida: 1.1683\n",
            "Época 216, Pérdida: 1.1554\n",
            "Época 217, Pérdida: 1.2336\n",
            "Época 218, Pérdida: 1.1236\n",
            "Época 219, Pérdida: 1.1486\n",
            "Época 220, Pérdida: 1.1481, AUC Validación: 0.7428, Precisión Validación: 0.7708\n",
            "Época 221, Pérdida: 1.1841\n",
            "Época 222, Pérdida: 1.1497\n",
            "Época 223, Pérdida: 1.0997\n",
            "Época 224, Pérdida: 1.0786\n",
            "Época 225, Pérdida: 1.1508\n",
            "Época 226, Pérdida: 1.0921\n",
            "Época 227, Pérdida: 1.1479\n",
            "Época 228, Pérdida: 1.0626\n",
            "Época 229, Pérdida: 1.1027\n",
            "Época 230, Pérdida: 1.0970, AUC Validación: 0.7475, Precisión Validación: 0.7708\n",
            "Época 231, Pérdida: 1.0555\n",
            "Época 232, Pérdida: 1.0669\n",
            "Época 233, Pérdida: 1.1278\n",
            "Época 234, Pérdida: 1.0708\n",
            "Época 235, Pérdida: 1.0617\n",
            "Época 236, Pérdida: 1.0206\n",
            "Época 237, Pérdida: 1.0063\n",
            "Época 238, Pérdida: 1.0551\n",
            "Época 239, Pérdida: 1.0423\n",
            "Época 240, Pérdida: 1.0780, AUC Validación: 0.7536, Precisión Validación: 0.7708\n",
            "Época 241, Pérdida: 1.0320\n",
            "Época 242, Pérdida: 1.0221\n",
            "Época 243, Pérdida: 1.0195\n",
            "Época 244, Pérdida: 0.9809\n",
            "Época 245, Pérdida: 0.9963\n",
            "Época 246, Pérdida: 1.0297\n",
            "Época 247, Pérdida: 1.0339\n",
            "Época 248, Pérdida: 1.0289\n",
            "Época 249, Pérdida: 1.0190\n",
            "Época 250, Pérdida: 1.0122, AUC Validación: 0.7523, Precisión Validación: 0.7708\n",
            "Época 251, Pérdida: 0.9857\n",
            "Época 252, Pérdida: 1.0175\n",
            "Época 253, Pérdida: 0.9602\n",
            "Época 254, Pérdida: 0.9582\n",
            "Época 255, Pérdida: 1.0223\n",
            "Época 256, Pérdida: 0.9607\n",
            "Época 257, Pérdida: 1.0309\n",
            "Época 258, Pérdida: 0.9628\n",
            "Época 259, Pérdida: 0.9378\n",
            "Época 260, Pérdida: 0.9280, AUC Validación: 0.7494, Precisión Validación: 0.7668\n",
            "Época 261, Pérdida: 0.9362\n",
            "Época 262, Pérdida: 0.9864\n",
            "Época 263, Pérdida: 0.9236\n",
            "Época 264, Pérdida: 0.9134\n",
            "Época 265, Pérdida: 0.9246\n",
            "Época 266, Pérdida: 0.9261\n",
            "Época 267, Pérdida: 0.9073\n",
            "Época 268, Pérdida: 0.9281\n",
            "Época 269, Pérdida: 0.9787\n",
            "Época 270, Pérdida: 0.8875, AUC Validación: 0.7465, Precisión Validación: 0.7668\n",
            "Época 271, Pérdida: 0.9170\n",
            "Época 272, Pérdida: 0.9424\n",
            "Época 273, Pérdida: 0.9129\n",
            "Época 274, Pérdida: 0.8888\n",
            "Época 275, Pérdida: 0.8871\n",
            "Época 276, Pérdida: 0.9773\n",
            "Época 277, Pérdida: 0.8649\n",
            "Época 278, Pérdida: 0.9318\n",
            "Época 279, Pérdida: 0.9038\n",
            "Época 280, Pérdida: 0.9348, AUC Validación: 0.7489, Precisión Validación: 0.7628\n",
            "Época 281, Pérdida: 0.8751\n",
            "Época 282, Pérdida: 0.9170\n",
            "Época 283, Pérdida: 0.8735\n",
            "Época 284, Pérdida: 0.8591\n",
            "Época 285, Pérdida: 0.9151\n",
            "Época 286, Pérdida: 0.8847\n",
            "Época 287, Pérdida: 0.8850\n",
            "Época 288, Pérdida: 0.8287\n",
            "Época 289, Pérdida: 0.8744\n",
            "Época 290, Pérdida: 0.8635, AUC Validación: 0.7513, Precisión Validación: 0.7628\n",
            "Época 291, Pérdida: 0.8659\n",
            "Época 292, Pérdida: 0.8872\n",
            "Época 293, Pérdida: 0.9084\n",
            "Época 294, Pérdida: 0.8152\n",
            "Época 295, Pérdida: 0.8932\n",
            "Época 296, Pérdida: 0.8664\n",
            "Época 297, Pérdida: 0.8630\n",
            "Época 298, Pérdida: 0.8579\n",
            "Época 299, Pérdida: 0.8781\n",
            "Época 300, Pérdida: 0.8204, AUC Validación: 0.7550, Precisión Validación: 0.7628\n",
            "Época 301, Pérdida: 0.8461\n",
            "Época 302, Pérdida: 0.9065\n",
            "Época 303, Pérdida: 0.8937\n",
            "Época 304, Pérdida: 0.8938\n",
            "Época 305, Pérdida: 0.8241\n",
            "Época 306, Pérdida: 0.8389\n",
            "Época 307, Pérdida: 0.8483\n",
            "Época 308, Pérdida: 0.8768\n",
            "Época 309, Pérdida: 0.8338\n",
            "Época 310, Pérdida: 0.8200, AUC Validación: 0.7518, Precisión Validación: 0.7549\n",
            "Época 311, Pérdida: 0.8232\n",
            "Época 312, Pérdida: 0.8146\n",
            "Época 313, Pérdida: 0.8325\n",
            "Época 314, Pérdida: 0.7921\n",
            "Época 315, Pérdida: 0.8108\n",
            "Época 316, Pérdida: 0.8017\n",
            "Época 317, Pérdida: 0.7999\n",
            "Época 318, Pérdida: 0.8624\n",
            "Época 319, Pérdida: 0.8115\n",
            "Época 320, Pérdida: 0.8125, AUC Validación: 0.7530, Precisión Validación: 0.7668\n",
            "Época 321, Pérdida: 0.8586\n",
            "Época 322, Pérdida: 0.7811\n",
            "Época 323, Pérdida: 0.7618\n",
            "Época 324, Pérdida: 0.8138\n",
            "Época 325, Pérdida: 0.7790\n",
            "Época 326, Pérdida: 0.7902\n",
            "Época 327, Pérdida: 0.7864\n",
            "Época 328, Pérdida: 0.7910\n",
            "Época 329, Pérdida: 0.7788\n",
            "Época 330, Pérdida: 0.8220, AUC Validación: 0.7511, Precisión Validación: 0.7708\n",
            "Época 331, Pérdida: 0.7817\n",
            "Época 332, Pérdida: 0.7727\n",
            "Época 333, Pérdida: 0.8144\n",
            "Época 334, Pérdida: 0.7833\n",
            "Época 335, Pérdida: 0.7752\n",
            "Época 336, Pérdida: 0.7710\n",
            "Época 337, Pérdida: 0.7590\n",
            "Época 338, Pérdida: 0.7518\n",
            "Época 339, Pérdida: 0.7894\n",
            "Época 340, Pérdida: 0.7648, AUC Validación: 0.7527, Precisión Validación: 0.7747\n",
            "Época 341, Pérdida: 0.7764\n",
            "Época 342, Pérdida: 0.8193\n",
            "Época 343, Pérdida: 0.7491\n",
            "Época 344, Pérdida: 0.7632\n",
            "Época 345, Pérdida: 0.7262\n",
            "Época 346, Pérdida: 0.7820\n",
            "Época 347, Pérdida: 0.8033\n",
            "Época 348, Pérdida: 0.7833\n",
            "Época 349, Pérdida: 0.7481\n",
            "Época 350, Pérdida: 0.7621, AUC Validación: 0.7526, Precisión Validación: 0.7747\n",
            "Época 351, Pérdida: 0.7438\n",
            "Época 352, Pérdida: 0.7871\n",
            "Época 353, Pérdida: 0.7533\n",
            "Época 354, Pérdida: 0.7708\n",
            "Época 355, Pérdida: 0.7505\n",
            "Época 356, Pérdida: 0.7747\n",
            "Época 357, Pérdida: 0.7543\n",
            "Época 358, Pérdida: 0.7710\n",
            "Época 359, Pérdida: 0.7122\n",
            "Época 360, Pérdida: 0.7363, AUC Validación: 0.7511, Precisión Validación: 0.7787\n",
            "Época 361, Pérdida: 0.7025\n",
            "Época 362, Pérdida: 0.7427\n",
            "Época 363, Pérdida: 0.7370\n",
            "Época 364, Pérdida: 0.7591\n",
            "Época 365, Pérdida: 0.7298\n",
            "Época 366, Pérdida: 0.7227\n",
            "Época 367, Pérdida: 0.7162\n",
            "Época 368, Pérdida: 0.7471\n",
            "Época 369, Pérdida: 0.7619\n",
            "Época 370, Pérdida: 0.7639, AUC Validación: 0.7511, Precisión Validación: 0.7787\n",
            "Época 371, Pérdida: 0.7132\n",
            "Época 372, Pérdida: 0.7721\n",
            "Época 373, Pérdida: 0.7180\n",
            "Época 374, Pérdida: 0.7225\n",
            "Época 375, Pérdida: 0.6977\n",
            "Época 376, Pérdida: 0.7567\n",
            "Época 377, Pérdida: 0.7210\n",
            "Época 378, Pérdida: 0.7084\n",
            "Época 379, Pérdida: 0.7093\n",
            "Época 380, Pérdida: 0.7301, AUC Validación: 0.7546, Precisión Validación: 0.7668\n",
            "Época 381, Pérdida: 0.6910\n",
            "Época 382, Pérdida: 0.7193\n",
            "Época 383, Pérdida: 0.6840\n",
            "Época 384, Pérdida: 0.7137\n",
            "Época 385, Pérdida: 0.7164\n",
            "Época 386, Pérdida: 0.6731\n",
            "Época 387, Pérdida: 0.7094\n",
            "Época 388, Pérdida: 0.6899\n",
            "Época 389, Pérdida: 0.7093\n",
            "Época 390, Pérdida: 0.7052, AUC Validación: 0.7528, Precisión Validación: 0.7708\n",
            "Época 391, Pérdida: 0.7177\n",
            "Época 392, Pérdida: 0.7048\n",
            "Época 393, Pérdida: 0.6891\n",
            "Época 394, Pérdida: 0.6919\n",
            "Época 395, Pérdida: 0.7192\n",
            "Época 396, Pérdida: 0.6966\n",
            "Época 397, Pérdida: 0.6887\n",
            "Época 398, Pérdida: 0.7069\n",
            "Época 399, Pérdida: 0.7157\n",
            "Época 400, Pérdida: 0.7233, AUC Validación: 0.7567, Precisión Validación: 0.7668\n",
            "Época 401, Pérdida: 0.7131\n",
            "Época 402, Pérdida: 0.7074\n",
            "Época 403, Pérdida: 0.6760\n",
            "Época 404, Pérdida: 0.6732\n",
            "Época 405, Pérdida: 0.6998\n",
            "Época 406, Pérdida: 0.7075\n",
            "Época 407, Pérdida: 0.7031\n",
            "Época 408, Pérdida: 0.6705\n",
            "Época 409, Pérdida: 0.6659\n",
            "Época 410, Pérdida: 0.7061, AUC Validación: 0.7585, Precisión Validación: 0.7708\n",
            "Época 411, Pérdida: 0.6794\n",
            "Época 412, Pérdida: 0.6937\n",
            "Época 413, Pérdida: 0.6913\n",
            "Época 414, Pérdida: 0.6739\n",
            "Época 415, Pérdida: 0.6485\n",
            "Época 416, Pérdida: 0.6851\n",
            "Época 417, Pérdida: 0.6549\n",
            "Época 418, Pérdida: 0.7190\n",
            "Época 419, Pérdida: 0.6576\n",
            "Época 420, Pérdida: 0.6670, AUC Validación: 0.7505, Precisión Validación: 0.7668\n",
            "Época 421, Pérdida: 0.6653\n",
            "Época 422, Pérdida: 0.6435\n",
            "Época 423, Pérdida: 0.6599\n",
            "Época 424, Pérdida: 0.6628\n",
            "Época 425, Pérdida: 0.6698\n",
            "Época 426, Pérdida: 0.6818\n",
            "Época 427, Pérdida: 0.6867\n",
            "Época 428, Pérdida: 0.6706\n",
            "Época 429, Pérdida: 0.6691\n",
            "Época 430, Pérdida: 0.6492, AUC Validación: 0.7564, Precisión Validación: 0.7668\n",
            "Época 431, Pérdida: 0.6768\n",
            "Época 432, Pérdida: 0.6553\n",
            "Época 433, Pérdida: 0.6544\n",
            "Época 434, Pérdida: 0.6743\n",
            "Época 435, Pérdida: 0.6810\n",
            "Época 436, Pérdida: 0.6496\n",
            "Época 437, Pérdida: 0.6455\n",
            "Época 438, Pérdida: 0.6431\n",
            "Época 439, Pérdida: 0.6663\n",
            "Época 440, Pérdida: 0.6589, AUC Validación: 0.7536, Precisión Validación: 0.7668\n",
            "Época 441, Pérdida: 0.6570\n",
            "Época 442, Pérdida: 0.6405\n",
            "Época 443, Pérdida: 0.6568\n",
            "Época 444, Pérdida: 0.6590\n",
            "Época 445, Pérdida: 0.6404\n",
            "Época 446, Pérdida: 0.6485\n",
            "Época 447, Pérdida: 0.6487\n",
            "Época 448, Pérdida: 0.6498\n",
            "Época 449, Pérdida: 0.6562\n",
            "Época 450, Pérdida: 0.6553, AUC Validación: 0.7558, Precisión Validación: 0.7708\n",
            "Época 451, Pérdida: 0.6491\n",
            "Época 452, Pérdida: 0.6343\n",
            "Época 453, Pérdida: 0.6382\n",
            "Época 454, Pérdida: 0.6163\n",
            "Época 455, Pérdida: 0.6413\n",
            "Época 456, Pérdida: 0.6521\n",
            "Época 457, Pérdida: 0.6699\n",
            "Época 458, Pérdida: 0.6678\n",
            "Época 459, Pérdida: 0.6563\n",
            "Época 460, Pérdida: 0.6629, AUC Validación: 0.7581, Precisión Validación: 0.7787\n",
            "Época 461, Pérdida: 0.6631\n",
            "Época 462, Pérdida: 0.6410\n",
            "Época 463, Pérdida: 0.6381\n",
            "Época 464, Pérdida: 0.6548\n",
            "Época 465, Pérdida: 0.6430\n",
            "Época 466, Pérdida: 0.6343\n",
            "Época 467, Pérdida: 0.6420\n",
            "Época 468, Pérdida: 0.6329\n",
            "Época 469, Pérdida: 0.6441\n",
            "Época 470, Pérdida: 0.6198, AUC Validación: 0.7545, Precisión Validación: 0.7708\n",
            "Época 471, Pérdida: 0.6264\n",
            "Época 472, Pérdida: 0.6356\n",
            "Época 473, Pérdida: 0.6357\n",
            "Época 474, Pérdida: 0.6550\n",
            "Época 475, Pérdida: 0.6329\n",
            "Época 476, Pérdida: 0.6340\n",
            "Época 477, Pérdida: 0.6462\n",
            "Época 478, Pérdida: 0.6452\n",
            "Época 479, Pérdida: 0.6170\n",
            "Época 480, Pérdida: 0.6395, AUC Validación: 0.7570, Precisión Validación: 0.7787\n",
            "Época 481, Pérdida: 0.6243\n",
            "Época 482, Pérdida: 0.6117\n",
            "Época 483, Pérdida: 0.6341\n",
            "Época 484, Pérdida: 0.6224\n",
            "Época 485, Pérdida: 0.6406\n",
            "Época 486, Pérdida: 0.6122\n",
            "Época 487, Pérdida: 0.6335\n",
            "Época 488, Pérdida: 0.6269\n",
            "Época 489, Pérdida: 0.6215\n",
            "Época 490, Pérdida: 0.6265, AUC Validación: 0.7548, Precisión Validación: 0.7787\n",
            "Época 491, Pérdida: 0.6256\n",
            "Época 492, Pérdida: 0.6371\n",
            "Época 493, Pérdida: 0.6222\n",
            "Época 494, Pérdida: 0.6384\n",
            "Época 495, Pérdida: 0.6120\n",
            "Época 496, Pérdida: 0.6300\n",
            "Época 497, Pérdida: 0.6098\n",
            "Época 498, Pérdida: 0.6265\n",
            "Época 499, Pérdida: 0.6117\n",
            "Época 500, Pérdida: 0.6071, AUC Validación: 0.7561, Precisión Validación: 0.7747\n",
            "Época 501, Pérdida: 0.6195\n",
            "Época 502, Pérdida: 0.6175\n",
            "Época 503, Pérdida: 0.6063\n",
            "Época 504, Pérdida: 0.6048\n",
            "Época 505, Pérdida: 0.5978\n",
            "Época 506, Pérdida: 0.5952\n",
            "Época 507, Pérdida: 0.6137\n",
            "Época 508, Pérdida: 0.6250\n",
            "Época 509, Pérdida: 0.6202\n",
            "Época 510, Pérdida: 0.6058, AUC Validación: 0.7547, Precisión Validación: 0.7787\n",
            "Época 511, Pérdida: 0.6065\n",
            "Época 512, Pérdida: 0.6001\n",
            "Época 513, Pérdida: 0.6243\n",
            "Época 514, Pérdida: 0.6264\n",
            "Época 515, Pérdida: 0.6055\n",
            "Época 516, Pérdida: 0.6241\n",
            "Época 517, Pérdida: 0.5902\n",
            "Época 518, Pérdida: 0.6141\n",
            "Época 519, Pérdida: 0.6033\n",
            "Época 520, Pérdida: 0.6098, AUC Validación: 0.7554, Precisión Validación: 0.7708\n",
            "Época 521, Pérdida: 0.5968\n",
            "Época 522, Pérdida: 0.6070\n",
            "Época 523, Pérdida: 0.6056\n",
            "Época 524, Pérdida: 0.6274\n",
            "Época 525, Pérdida: 0.6093\n",
            "Época 526, Pérdida: 0.6220\n",
            "Época 527, Pérdida: 0.6118\n",
            "Época 528, Pérdida: 0.6048\n",
            "Época 529, Pérdida: 0.5903\n",
            "Época 530, Pérdida: 0.5828, AUC Validación: 0.7582, Precisión Validación: 0.7747\n",
            "Época 531, Pérdida: 0.6144\n",
            "Época 532, Pérdida: 0.6124\n",
            "Época 533, Pérdida: 0.6059\n",
            "Época 534, Pérdida: 0.5823\n",
            "Época 535, Pérdida: 0.5970\n",
            "Época 536, Pérdida: 0.5888\n",
            "Época 537, Pérdida: 0.6096\n",
            "Época 538, Pérdida: 0.5986\n",
            "Época 539, Pérdida: 0.5947\n",
            "Época 540, Pérdida: 0.5784, AUC Validación: 0.7603, Precisión Validación: 0.7787\n",
            "Época 541, Pérdida: 0.6060\n",
            "Época 542, Pérdida: 0.6099\n",
            "Época 543, Pérdida: 0.5889\n",
            "Época 544, Pérdida: 0.5969\n",
            "Época 545, Pérdida: 0.5850\n",
            "Época 546, Pérdida: 0.5867\n",
            "Época 547, Pérdida: 0.5905\n",
            "Época 548, Pérdida: 0.6017\n",
            "Época 549, Pérdida: 0.5826\n",
            "Época 550, Pérdida: 0.5953, AUC Validación: 0.7581, Precisión Validación: 0.7747\n",
            "Época 551, Pérdida: 0.6011\n",
            "Época 552, Pérdida: 0.5874\n",
            "Época 553, Pérdida: 0.6051\n",
            "Época 554, Pérdida: 0.5885\n",
            "Época 555, Pérdida: 0.5761\n",
            "Época 556, Pérdida: 0.5713\n",
            "Época 557, Pérdida: 0.5814\n",
            "Época 558, Pérdida: 0.5708\n",
            "Época 559, Pérdida: 0.5776\n",
            "Época 560, Pérdida: 0.5908, AUC Validación: 0.7539, Precisión Validación: 0.7787\n",
            "Época 561, Pérdida: 0.5787\n",
            "Época 562, Pérdida: 0.5761\n",
            "Época 563, Pérdida: 0.5927\n",
            "Época 564, Pérdida: 0.5605\n",
            "Época 565, Pérdida: 0.5831\n",
            "Época 566, Pérdida: 0.5848\n",
            "Época 567, Pérdida: 0.5940\n",
            "Época 568, Pérdida: 0.5741\n",
            "Época 569, Pérdida: 0.5708\n",
            "Época 570, Pérdida: 0.5717, AUC Validación: 0.7543, Precisión Validación: 0.7787\n",
            "Época 571, Pérdida: 0.5792\n",
            "Época 572, Pérdida: 0.5721\n",
            "Época 573, Pérdida: 0.5801\n",
            "Época 574, Pérdida: 0.5862\n",
            "Época 575, Pérdida: 0.5876\n",
            "Época 576, Pérdida: 0.5803\n",
            "Época 577, Pérdida: 0.5752\n",
            "Época 578, Pérdida: 0.5737\n",
            "Época 579, Pérdida: 0.5807\n",
            "Época 580, Pérdida: 0.5749, AUC Validación: 0.7506, Precisión Validación: 0.7826\n",
            "Época 581, Pérdida: 0.5923\n",
            "Época 582, Pérdida: 0.5601\n",
            "Época 583, Pérdida: 0.5751\n",
            "Época 584, Pérdida: 0.5728\n",
            "Época 585, Pérdida: 0.5636\n",
            "Época 586, Pérdida: 0.5688\n",
            "Época 587, Pérdida: 0.5699\n",
            "Época 588, Pérdida: 0.5829\n",
            "Época 589, Pérdida: 0.5679\n",
            "Época 590, Pérdida: 0.5530, AUC Validación: 0.7546, Precisión Validación: 0.7826\n",
            "Época 591, Pérdida: 0.5642\n",
            "Época 592, Pérdida: 0.5721\n",
            "Época 593, Pérdida: 0.5837\n",
            "Época 594, Pérdida: 0.5693\n",
            "Época 595, Pérdida: 0.5841\n",
            "Época 596, Pérdida: 0.5662\n",
            "Época 597, Pérdida: 0.5607\n",
            "Época 598, Pérdida: 0.5596\n",
            "Época 599, Pérdida: 0.5743\n",
            "Época 600, Pérdida: 0.5502, AUC Validación: 0.7535, Precisión Validación: 0.7826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "def evaluate(data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model(data.x, data.edge_index)\n",
        "        scores = model.predict_link(z, data.edge_label_index).sigmoid()\n",
        "        labels = data.edge_label\n",
        "        auc = roc_auc_score(labels.cpu(), scores.cpu())\n",
        "        preds = (scores > 0.5).float()\n",
        "        acc = accuracy_score(labels.cpu(), preds.cpu())\n",
        "    return auc, acc\n",
        "\n",
        "val_auc, val_acc = evaluate(val_data)\n",
        "print(f'Validación - AUC: {val_auc:.4f}, Precisión: {val_acc:.4f}')"
      ],
      "metadata": {
        "id": "cACsbzksqRo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4377db06-b675-41f6-9edc-0b5824fdc8e4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validación - AUC: 0.7603, Precisión: 0.7787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el mejor modelo guardado\n",
        "model.load_state_dict(best_model)\n",
        "model.eval()  # Poner el modelo en modo evaluación\n",
        "\n",
        "# Obtener los embeddings de todos los nodos\n",
        "with torch.no_grad():\n",
        "    z = model(data.x, data.edge_index)  # z contiene los embeddings de todos los nodos"
      ],
      "metadata": {
        "id": "N399H7_XKk-O"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_links(node_idx, top_k=5):\n",
        "    \"\"\"\n",
        "    Predice las top_k conexiones más probables para un nodo dado\n",
        "\n",
        "    Args:\n",
        "        node_idx: Índice del nodo (según tu mapeo)\n",
        "        top_k: Número de recomendaciones a devolver\n",
        "    \"\"\"\n",
        "    # Calcular similitud entre el nodo y todos los demás\n",
        "    similarities = torch.matmul(z, z[node_idx].unsqueeze(1)).squeeze()\n",
        "\n",
        "    # Ordenar por similitud descendente\n",
        "    sorted_sims, indices = torch.sort(similarities, descending=True)\n",
        "\n",
        "    # Excluir el propio nodo y obtener los top_k\n",
        "    top_indices = indices[1:top_k+1]  # Excluye el primer elemento (él mismo)\n",
        "    top_sims = sorted_sims[1:top_k+1]\n",
        "\n",
        "    # Mapear índices numéricos a IDs originales si es necesario\n",
        "    # (Asumiendo que tienes un mapeo inverso)\n",
        "    inverse_mapping = {v: k for k, v in mapping.items()}\n",
        "\n",
        "    recommendations = []\n",
        "    for idx, sim in zip(top_indices, top_sims):\n",
        "        original_id = inverse_mapping[int(idx)]\n",
        "        recommendations.append((original_id, float(sim)))\n",
        "\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "nKfXqUR9MqS5"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_similar_emprendimientos(emprendimiento_id, top_k=5):\n",
        "    \"\"\"\n",
        "    Encuentra emprendimientos similares basado en los embeddings\n",
        "\n",
        "    Args:\n",
        "        emprendimiento_id: ID original del emprendimiento en tu base de datos\n",
        "        top_k: Número de recomendaciones a devolver\n",
        "    \"\"\"\n",
        "    # Convertir ID original a índice del grafo\n",
        "    node_idx = mapping[emprendimiento_id]\n",
        "\n",
        "    # Obtener recomendaciones\n",
        "    recommendations = predict_links(node_idx, top_k)\n",
        "\n",
        "    # Aquí puedes añadir más lógica para filtrar o procesar los resultados\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "IX7XwgW2MsKu"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supongamos que quieres recomendaciones para el emprendimiento con ID 123\n",
        "emprendimiento_id = 49\n",
        "\n",
        "try:\n",
        "    recomendaciones = find_similar_emprendimientos(emprendimiento_id, top_k=10)\n",
        "    print(f\"Recomendaciones para el emprendimiento {emprendimiento_id}:\")\n",
        "    for rec_id, sim_score in recomendaciones:\n",
        "        print(f\"ID: {rec_id}, Similitud: {sim_score:.4f}\")\n",
        "\n",
        "        # Aquí podrías añadir código para obtener más información de tu base de datos\n",
        "        # Por ejemplo:\n",
        "        # emprendimiento = obtener_emprendimiento_de_bd(rec_id)\n",
        "        # print(f\"Nombre: {emprendimiento['nombre']}, Descripción: {emprendimiento['descripcion'][:50]}...\")\n",
        "\n",
        "except KeyError:\n",
        "    print(f\"El emprendimiento con ID {emprendimiento_id} no está en el grafo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPkcZBhsMqw1",
        "outputId": "e2b88a81-6ef6-44a4-8cc6-0ddc5b8adc08"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recomendaciones para el emprendimiento 49:\n",
            "ID: 2, Similitud: 1.9422\n",
            "ID: 49, Similitud: 1.8283\n",
            "ID: 54, Similitud: 1.8035\n",
            "ID: 3, Similitud: 1.7518\n",
            "ID: 4, Similitud: 1.7227\n",
            "ID: 5, Similitud: 1.6123\n",
            "ID: 16, Similitud: 1.4740\n",
            "ID: 31, Similitud: 1.4528\n",
            "ID: 17, Similitud: 1.4512\n",
            "ID: 19, Similitud: 1.3885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "0PTnEvF8NUZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}